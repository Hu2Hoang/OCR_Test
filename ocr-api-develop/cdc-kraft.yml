version: '3.6'

volumes:
  zookeeper-data:
    driver: local
  zookeeper-log:
    driver: local
  kafka-data:
    driver: local 
    
services:
  # ------------------------------------------------------------ #
  # akhq: Kafka GUI for Apache Kafka to manage topics, 
  #       topics data, consumers group, schema registry, connect ..
  # ----------------- -------------------------------------------#
  akhq:
    image: tchiotludo/akhq
    restart: unless-stopped
    container_name: akhq
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "kafka:29092"
                security.protocol: "SASL_PLAINTEXT"
                sasl.mechanism: "PLAIN"
                sasl.jaas.config: "org.apache.kafka.common.security.plain.PlainLoginModule required username='admin' password='admin';"
              connect:
                - name: "connect"
                  url: "http://host.docker.internal:8083"

    ports:
      - 8080:8080
    links:
      - kafka
    networks:
      - MONGO
  # -----------------------------#
  # Zookeeper, Apache Kafka      #
  # ---------------------------- #

  # zookeeper:
  #   image: confluentinc/cp-zookeeper:${CONFLUENT_VERSION:-latest}
  #   restart: unless-stopped
  #   container_name: zookeeper
  #   volumes:
  #     - zookeeper-data:/var/lib/zookeeper/data:Z
  #     - zookeeper-log:/var/lib/zookeeper/log:Z
  #   environment:
  #     ZOOKEEPER_CLIENT_PORT: '2181'
  #     ZOOKEEPER_ADMIN_ENABLE_SERVER: 'false'
  #   networks:
  #     - MONGO 


  # kafka:
  #   image: confluentinc/cp-kafka:${CONFLUENT_VERSION:-latest}
  #   restart: unless-stopped
  #   container_name: kafka
  #   volumes:
  #     - kafka-data:/var/lib/kafka/data:Z
  #   environment:
  #     KAFKA_BROKER_ID: '0'
  #     KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
  #     KAFKA_NUM_PARTITIONS: '12'
  #     KAFKA_COMPRESSION_TYPE: 'gzip'
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: '1'
  #     KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: '1'
  #     KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: '1'
  #     KAFKA_ADVERTISED_LISTENERS: 'INTERNAL://kafka:9092,OUTSIDE://kafka:9093'
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
  #     KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: 'false'
  #     KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
  #     KAFKA_AUTHORIZER_CLASS_NAME: 'kafka.security.authorizer.AclAuthorizer'
  #     KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: 'true'
  #   links:
  #     - zookeeper
  #   networks:
  #     - MONGO


  kafka:
    image: bitnami/kafka:3.6
    restart: unless-stopped
    container_name: kafka
    ports:
      - "29092:29092"
      - "9092:9092"
      - "9093:9093"
    volumes:
      - D:\kafka_data:/bitnami/kafka
    environment:
      # KRaft settings
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@host.docker.internal:9093
      # Client credentials
      - KAFKA_CLIENT_USERS=admin
      - KAFKA_CLIENT_PASSWORDS=admin
      - KAFKA_CLIENT_LISTENER_NAME=LISTENER_EXTERNAL
      # Controller credentials
      - KAFKA_CONTROLLER_USER=admin
      - KAFKA_CONTROLLER_PASSWORD=admin
      - KAFKA_CFG_SASL_MECHANISM_CONTROLLER_PROTOCOL=PLAIN
      # Inter-broker credentials
      - KAFKA_INTER_BROKER_USER=admin
      - KAFKA_INTER_BROKER_PASSWORD=admin
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=LISTENER_DOCKER
      - KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL=PLAIN
      # Listeners
        # Specify Container Local port
      - KAFKA_CFG_LISTENERS=LISTENER_DOCKER://:29092,LISTENER_EXTERNAL://:9092,CONTROLLER://:9093
        # Specify Host:Port for the Client to connect
        # Using kafka UI or other services that run in Docker: connect to host.docker.internal:29092
        # Services running on host: connect to localhost:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=LISTENER_DOCKER://host.docker.internal:29092,LISTENER_EXTERNAL://localhost:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:SASL_PLAINTEXT,LISTENER_DOCKER:SASL_PLAINTEXT,LISTENER_EXTERNAL:SASL_PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
    networks:
      - MONGO
  # schema-registry:
  #   image: confluentinc/cp-schema-registry:latest
  #   container_name: schema-registry
  #   depends_on:
  #     - kafka
  #   ports:
  #     - 8085:8085
  #   environment:
  #     # SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka:29092"
  #     # SCHEMA_REGISTRY_LISTENER: "http://0.0.0.0:8085"
  #     SCHEMA_REGISTRY_HOST_NAME: "schema-registry"
  #     SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_METHOD: "GET, POST, PUT, DELETE, OPTIONS"
  #     SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "SASL_PLAINTEXT://kafka:9093"
  #     SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8085"
  #     SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: SASL_PLAINTEXT
  #     SCHEMA_REGISTRY_KAFKASTORE_SASL_MECHANISM: PLAIN
  #     SCHEMA_REGISTRY_KAFKASTORE_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username='admin' password='admin';"

  #   networks:
  #     - MONGO


  # schema-registry:
  #   image: confluentinc/cp-schema-registry:latest
  #   hostname: schema-registry
  #   container_name: schema-registry
  #   depends_on:
  #     - kafka
  #   ports:
  #     - "8085:8085"
  #   environment:
  #     SCHEMA_REGISTRY_HOST_NAME: schema-registry
  #     # SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper:2181'
  #     SCHEMA_REGISTRY_LISTENERS: http://schema-registry:8085
  #     SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:29092
  #     SCHEMA_REGISTRY_DEBUG: 'true'
  #     SCHEMA_REGISTRY_KAFKASTORE_SASL_MECHANISM: PLAIN
  #     SCHEMA_REGISTRY_KAFKASTORE_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username='admin' password='admin';"
  #   networks:
  #     - MONGO

  # schema-registry:
  #   image: confluentinc/cp-schema-registry:${CONFLUENT_VERSION:-latest}
  #   restart: unless-stopped
  #   depends_on:
  #     - kafka
  #   environment:
  #     SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka:29092'
  #     SCHEMA_REGISTRY_HOST_NAME: 'schema-registry'
  #     SCHEMA_REGISTRY_LISTENERS: 'http://0.0.0.0:8085'
  #     SCHEMA_REGISTRY_KAFKASTORE_SASL_MECHANISM: PLAIN
  #     SCHEMA_REGISTRY_KAFKASTORE_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username='admin' password='admin';"

  schema-registry:
    image: confluentinc/cp-schema-registry:${CONFLUENT_VERSION:-latest}
    container_name: schema-registry
    restart: unless-stopped
    depends_on:
      - kafka
    ports:
      - "8085:8085"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: 'schema-registry'
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka:29092'
      SCHEMA_REGISTRY_LISTENERS: 'http://0.0.0.0:8085'
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: "SASL_PLAINTEXT"
      SCHEMA_REGISTRY_KAFKASTORE_SASL_MECHANISM: "PLAIN"
      SCHEMA_REGISTRY_KAFKASTORE_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username='admin' password='admin';"
    networks:
      - MONGO

  # -----------------------------#
  # Kafka Connect                #
  # ---------------------------- #

  connect:
    image: confluentinc/cp-kafka-connect:${CONFLUENT_VERSION:-latest}
    container_name: connect
    restart: unless-stopped
    ports:
      - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'kafka:29092'
      CONNECT_REST_PORT: 8083
      CONNECT_REST_ADVERTISED_HOST_NAME: 'localhost'
      CONNECT_CONFIG_STORAGE_TOPIC: '__connect-config'
      CONNECT_OFFSET_STORAGE_TOPIC: '__connect-offsets'
      CONNECT_STATUS_STORAGE_TOPIC: '__connect-status'
      CONNECT_GROUP_ID: 'kafka-connect'
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: 'true'
      CONNECT_KEY_CONVERTER: 'io.confluent.connect.avro.AvroConverter'
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8085'
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: 'true'
      CONNECT_VALUE_CONVERTER: 'io.confluent.connect.avro.AvroConverter'
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8085'
      CONNECT_INTERNAL_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_INTERNAL_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: '1'
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: '1'
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: '1'
      CONNECT_PLUGIN_PATH: /usr/share/java/,/etc/kafka-connect/jars
      CONNECT_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
      CONNECT_SASL_MECHANISM: 'PLAIN'
      CONNECT_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username='admin' password='admin';"
    volumes:
      - ./kafka-jars:/etc/kafka-connect/jars
    networks:
      - MONGO

  # -------------------------------------------------#
  # Create 3 mongo servers that will act as replicas #
  # -------------------------------------------------#

  mongo1:
    hostname: mongo1
    container_name: mongo1
    image: mongo
    expose:
      - 27017
    ports:
      - 30001:27017 
    restart: always
    command: mongod --replSet my-mongo-set
    networks:
      - MONGO
  mongo2:
    hostname: mongo2
    container_name: mongo2
    image: mongo
    expose:
      - 27017
    ports:
      - 30002:27017
    restart: always
    command: mongod --replSet my-mongo-set
    networks:
      - MONGO
  mongo3:
    hostname: mongo3
    container_name: mongo3
    image: mongo
    expose:
      - 27017
    ports:
      - 30003:27017
    restart: always
    command: mongod --replSet my-mongo-set
    networks:
      - MONGO

  # -------------------------------------------------------------#  
  # Define the initialization server
  # that runs the `rs.initiate` command to intialize
  # the replica set and connect the three servers to each other
  # -------------------------------------------------------------#  

  mongoinit:
    image: mongo
    # this container will exit after executing the command
    restart: "no"
    depends_on:
      - mongo1
      - mongo2
      - mongo3
    networks:
      - MONGO
    command: >
      mongosh --host host.docker.internal:30001 --eval 
      '
      db = (new Mongo("host.docker.internal:30001")).getDB("test");
      config = {
      "_id" : "my-mongo-set",
      "members" : [
        {
          "_id" : 0,
          "host" : "mongo1:27017"
        },
        {
          "_id" : 1,
          "host" : "mongo2:27017"
        },
        {
          "_id" : 2,
          "host" : "mongo3:27017"
        }
      ]
      };
      rs.initiate(config);
      '      
 

  # -----------------------------#
  # Mongo Express                #
  # ---------------------------- # 
  mongo-express:
    image: mongo-express:latest
    container_name: mongo-express
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: admin
      ME_CONFIG_MONGODB_ADMINPASSWORD: password
      ME_CONFIG_MONGODB_SERVER: host.docker.internal
      ME_CONFIG_MONGODB_PORT: "30001,30002,30003"
    ports:
      - "0.0.0.0:8081:8081"
    networks:
      - MONGO
    depends_on:
      - mongo1
      - mongo2
      - mongo3
 

networks:
  MONGO:
    driver: bridge